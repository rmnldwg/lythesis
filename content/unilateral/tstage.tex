\providecommand{\relativeRoot}{../..}
\documentclass[\relativeRoot/main.tex]{subfiles}
\graphicspath{{\subfix{./figures/}}}


\begin{document}

\section{Incorporation of T-stage}
\label{sec:unilateral:tstage}

We have introduced the \gls{hmm} with the promise that it could handle the concept of T-stages through its explicit modeling of dynamic processes. To keep up with that, we will now explain how this is achieved using the time-prior $p(t)$.

The core idea is to assume that early T-stage and late T-stage tumors share the same patterns of metastatic progression, except that late T-stage tumors are on average diagnosed at a later point in time, and thereby also show, on average, higher \gls{lnl} involvement. Formally, this can be described by assuming a different time-prior $p_T (t)$ for every T-stage $T$.  On the other hand, the transition matrix $\mathbf{A}$ is assumed to be the same for all T-stages.

For the inference of model parameters, the training data is split into subgroups according to T-stage. We now define a column-vector $\mathbf{f}_T$ separately for each T-stage, which counts the number of patients in the dataset that were diagnosed with one of the possible observational states and a given T-stage. The log-likelihood from which we want to sample is then simply a sum of the likelihoods as above, where the essential difference is that we equip each marginalization over time with a different time-prior $p_T (t)$, according to its T-stage:
%
\begin{equation} \label{eq:hmm_log_likelihood}
    \log{P \left( \boldsymbol{\mathcal{Z}} \mid \theta \right)} = \sum_{T=1}^{4}{\log{\left[ \sum_{t = 0}^{t_\text{max}}{p_T (t) \cdot \boldsymbol{\pi}^\top \cdot (\mathbf{A})^t \cdot \mathbf{B}} \right]} \cdot \mathbf{f}_T}
\end{equation}
%
The logarithm must be taken element-wise for the resulting row-vector inside the square brackets. The only data-dependent term here is the vector $\mathbf{f}_T$ counting the occurrences of all possible observations. It is again important to note that the only difference between the part of the log-likelihood for the different T-stages is the exact shape or parametrization of the time-prior. The transition probabilities, and hence also the transition matrix $\mathbf{A}$, are the same for all T-stages. For this to work, we rely on the assumption that different typical patterns of nodal involvement for the same primary tumor location are caused mainly by different progression times

At this point, it makes sense to briefly introduce a notation of the above equation that is more suitable for the actual programmatic implementation of the inference and the extension we will discuss later. We can rewrite the term in the square brackets of \cref{eq:hmm_log_likelihood} by using the matrix
%
\begin{equation} \label{eq:hmm_matrix_lambda}
    \boldsymbol{\Lambda} \coloneqq 
    P \left( \mathbf{X} \mid \mathbf{t} \right) = 
    \begin{pmatrix}
        \boldsymbol{\pi}^\top \cdot \left( \mathbf{A} \right)^0 \\
        \boldsymbol{\pi}^\top \cdot \left( \mathbf{A} \right)^1 \\
        \vdots \\
        \boldsymbol{\pi}^\top \cdot \left( \mathbf{A} \right)^{t_\text{max}}
    \end{pmatrix}
\end{equation}
%
where row number $t$ corresponds to the vector $\boldsymbol{\pi}^\top \cdot \left( \mathbf{A} \right)^t$, i.e. the probabilities for all possible hidden states, given the diagnose time. So, the element $\boldsymbol{\Lambda}_{ti}$ corresponds to the probability $P \left( \boldsymbol{\xi}_i \mid t \right)$ of a patient arriving in the $i$th state after $t$ time steps. With this, we can rewrite the term in the square brackets of \cref{eq:hmm_log_likelihood} purely as a product of vectors and matrices:
%
\begin{equation}
    \sum_{t = 0}^{t_\text{max}}{p_T (t) \cdot \boldsymbol{\pi}^\top \cdot (\mathbf{A})^t} = p_T \left( \mathbf{t} \right) \cdot \boldsymbol{\Lambda}
\end{equation}
%
with $p_T \left( \mathbf{t} \right) = \big( p_T(0) \quad p_T(1) \quad \cdots \quad p_T(t_\text{max}) \big)$. The matrix $\boldsymbol{\Lambda}$ implicitly depends on the spread probabilities, while each of the $p_T(\mathbf{t})$ depends on the respective parametrization of the time prior. They are the only objects that depend on the parameters $\theta$ and they are independent of the data.


\subsection*{* Interpretation of time-steps and time-priors}
\label{subsec:unilateral:tstage:interpretation}

To add more interpretability to the time-prior $p(t)$ introduced in \cref{sec:unilateral:marginalization}, we want to give some insights here to what we think the time-steps and the distribution over them is supposed to mean.

First, the time that passes in the real world between the abstract time-steps $t$ and $t+1$ should not be seen as a somewhat arbitrarily chosen fixed time, measured in days or weeks. To how much real-world time that corresponds for a specific patient is irrelevant for our risk assessment, although it might prove very valuable for other research on tumor growth. Also, the time between two time-steps does not need to be constant; the model makes no assumptions about this. It merely assumes the probability of transition between states to be the same from $t$ to $t+1$ and for all $t$.

The time-prior $p(t)$ is essentially the probability that a patient is diagnosed after exactly $t$ time-steps. If we knew how long a patient had cancer before getting diagnosed and we also knew how long a typical timestep for this patient and his/her type of cancer was, then we could just fix $p(t)=1$ for the appropriate number of time-steps $t$ and set $p(t') = 0, \forall t' \neq t$. Since it is likely almost never known, we need to spread the probability over a range of time-steps, reflecting the fact that the diagnose of cancer happens spontaneously, e.g. during a routine checkup.

\end{document}
