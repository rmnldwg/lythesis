\providecommand{\relativeRoot}{../..}
\documentclass[\relativeRoot/main.tex]{subfiles}
\graphicspath{{\subfix{./figures/}}}


\begin{document}

\section{Comparing bilateral models}
\label{sec:bilateral:model_comp}

Up to this point we have largely argued that the mixing parameter makes intuitive sense because of the thought experiment, where we moved the primary tumor from a clearly lateralized position closer and closer to the mid-sagittal plane, until it was perfectly symmetric w.r.t. that plane. However, we now need to actually test whether our arguments hold. For that, we decided to compare three models:

\begin{itemize}
    \item Model $\mathcal{M}_\text{ag}$, which is agnostic to the tumor's extension $\text{e}$ over the mid-sagittal plane and treats the contralateral base spread in the same way for all patients.
    \item Model $\mathcal{M}_\alpha$ that uses the linear combination of the ipsilateral base probabilities and the contralateral ones for the patients without mid-plane extension to describe the spread for tumors which do extend over that plane.
    \item Model $\mathcal{M}_\text{full}$, going even further by defining a completely independent set of contralateral base probabilities for the patients whose tumor extends over the mid-sagittal plane.
\end{itemize}

Essentially, we now want to know which of these three models does the best job of describing the data. Intuitively, one would argue that it must be $\mathcal{M}_\text{full}$, but this model is also more complex than the other two. A natural choice for a metric that incorporates both the accuracy of the model and a penalty for model complexity -- often also called \emph{Occam's razor} -- is the \emph{model evidence} \cite{aponte_introduction_2022}, which we introduced in \cref{sec:graph:model_comp}.

\subsection{Implementation}
\label{subsec:bilateral:model_comp:implementation}

\input{\subfix{../_databox.tex}}

\input{_reproducibility.tex}

To compare the introduced models $\mathcal{M}_\text{ag}$, $\mathcal{M}_\alpha$ and $\mathcal{M}_\text{full}$, we performed \gls{ti} with a ladder of 64 $\beta$ values with step sizes selected according to a fifth order power rule. For each of the steps in the ladder, we performed an ensemble sampling round using the \texttt{emcee} \cite{foreman-mackey_emcee_2013} Python package. The size of the ensemble -- consisting of so-called walkers that allow sampling in parallel and mutually influence each other's proposals -- was chosen to be 20 times the number of dimensions of the parameter space. We set the sampling algorithm to propose new samples according to a mixture of two procedures: with 80\% probability it selected a differential evolution move \cite{nelson_run_2013} and with 20\% probability a snooker move, also based on differential evolution \cite{ter_braak_differential_2008}. The reason for this choice was that in previous experiments, this combination of proposals yielded the fastest convergence of the chain. Every one of the 64 sampling rounds consisted of a burn-in phase lasting 1000 steps, followed by 250 steps of which every fifth step was kept for later analysis. This might seem like a relatively short chain, but since the change of the posterior we sampled from only changed very slightly from $\beta_j$ to $\beta_{j+1}$, fewer steps are required to reach convergence.

In the end, we kept $S = 50 \cdot 20 \cdot k$, where $k$ is the dimensionality of the model, samples for each of the 64 $\beta_j$. The dimensionality $k$ of the parameter spaces ranged from nine for the agnostic model $\mathcal{M}_\text{ag}$ over ten (mixing model $\mathcal{M}_\alpha$) to twelve in the case of the full model $\mathcal{M}_\text{full}$. Out of these $S$ samples we randomly drew $M = 1000$ per $\beta_j$ and integrated them over their range, yielding 1000 estimates for the log-evidence $\ln{Z}_l$ with $l \in [1, \ldots, M]$. Using this ensemble of estimates, we were able to compute both the mean and the standard deviation, giving us a simple measure of uncertainty for that value. We also computed the \gls{bic} from the samples drawn at $\beta_{64} = 1$, as introduced in \cref{sec:graph:model_comp:bic}.

We restricted ourselves to the bilateral modelling of the \glspl{lnl} II, III and IV, because contralaterally we rarely observe involvement outside those levels, and it drastically speeds up the inference process, when fewer \glspl{lnl} are considered.

\subsection{Results}
\label{subsec:bilateral:model_comp:results}

\begin{figure}
    \def\svgwidth{1.0\textwidth}
    \input{figures/ipsi-comp.pdf_tex}
    \caption[Comparison of ipsilateral prevalences]{
        Predicted prevalences (shaded histograms) and posterior beta distributions of observed prevalences (solid lines) for the ipsilateral levels II (blue), III (orange) and IV (green). These prevalences have each been plotted for early T-stage patients (top row) and late T-stage (bottom row) and for the three models $\mathcal{M}_\text{ag}$ (left column), $\mathcal{M}_\alpha$ (middle column) and for $\mathcal{M}_\text{full}$ (right column). The differences between the models are negligible.
    }
    \label{fig:bilateral:model_comp:ipsi}
\end{figure}

First, we wanted to make sure all three models are still able to describe the ipsilateral spread sufficiently well. We have plotted the prevalence our trained models predict in the forms of histograms against the Beta-posterior of the observed prevalence in the data (\cref{fig:bilateral:model_comp:ipsi}). These plots were created by computing the respective prevalence for samples drawn during the final 250 steps at the end of the \gls{ti} process of which every fifth step was discarded.

The shown differences between the model's predictions are negligible. For late T-stages (bottom row of \cref{fig:bilateral:model_comp:ipsi}) it seems as if the model that is agnostic to the tumor's extension over the mid-sagittal plane slightly overestimates the prevalence, while the other two models seem to match them better or underestimate them by a small amount. Overall the fit of all models ipsilaterally is very good and shows no indication that one model performs better than the other.

On the contralateral side, however, this does not hold anymore. Here, we do not only stratify the prevalence by T-stage, but also by midline extension. Naturally, this cannot be captured by the agnostic model $\mathcal{M}_\text{ag}$ since it lacks the ability of modelling this. What is of interest to us here is how the mixing model $\mathcal{M}_\alpha$ and the full model $\mathcal{M}_\text{full}$ fare against each other and whether their improvements in predicting contralateral spread are worth the additional complexity.

The overall prevalence of contralateral involvement is plotted in \cref{fig:bilateral:model_comp:contra}. Again, the three different models are depicted in their own column, and we have distinguished between four cases for each model: The prevalence of any contralateral involvement for patients with
\begin{enumerate*}[label={(\arabic*)}]
    \item early T-stage and a clearly lateralized tumor (blue histograms and curves),
    \item early T-stage with a tumor extending over the mid-sagittal plane (orange),
    \item late T-stage with, again, a lateralized tumor (green) and finally
    \item where the tumor is both in late T-stage and does extend over the mid-plane (red).
\end{enumerate*}

\begin{figure}
    \def\svgwidth{1.0\textwidth}
    \input{figures/contra-comp.pdf_tex}
    \caption[
        Comparison of contralateral prevalences
    ]{
        Predicted prevalences (shaded histograms) and posterior beta distributions of observed prevalences (solid lines) for the contralateral overall involvement (anything \emph{not} clinically N0, on that side of the neck). Predicted and observed prevalence for early T-stage is colored blue and orange, while for late T-stage it is green and red. The prevalence for patients whose tumor does not extend over the mid-sagittal line is labelled \texttt{noext} and colored blue or green, while the same quantity for those with said extension is labelled \texttt{ext} and colored orange and red. The three models $\mathcal{M}_\text{ag}$, $\mathcal{M}_\alpha$ and $\mathcal{M}_\text{full}$ are depicted in the left, middle and right panel respectively.
    }
    \label{fig:bilateral:model_comp:contra}
\end{figure}

As discussed, the agnostic model $\mathcal{M}_\text{ag}$ (left panel in \cref{fig:bilateral:model_comp:contra}) cannot model midline extension, and hence it must predict the same prevalence for the same scenario, regardless of the patient's mid-sagittal extension. Its spread probability rates from the tumor to the contralateral \glspl{lnl} can only attempt to find an average of the respective observed prevalence.

Interestingly, both the model using the mixing parameter $\alpha$ and the full model, which has in total six parameters to model the spread from the tumor to the contralateral \glspl{lnl}, overestimate the prevalence of contralateral, early T-stage involvement when the tumor extends over the mid-sagittal line. This might be because, of the displayed cases, this is the rarest one, so it makes sense for the model to put less attention to it. On the other hand, we believe the reason also relates to how the model treats the mid-plane extension in general: If this binary \gls{rv} is observed to be true, the model assumes increased spread probabilities from the primary tumor to the contralateral \glspl{lnl} from the onset of the disease (i.e., from time-step 0). Realistically, however, this is probably not how a typical patient's disease evolves. As tumors grow over time, in many cases they will not cross the mid-sagittal plane right after they started to form, but only when they are sufficiently large, as indicated by our data as well: Of the early T-stage tumors in the dataset, only 7\% (11 of 150) cross the mid-sagittal plane, while of the late T-stage tumors 58\% (79 of 137) have grown over into the contralateral half of the patient. Consequently, the spread from them to the contralateral side increases during the tumor's growth. The current model cannot capture this and therefore assumes early T-stage patient's contralateral spread to be larger than observed.

Despite this, the two models perform equally well regarding the overall contralateral spread. In combination with the unaffected capabilities to predict the ipsilateral prevalences, as shown in \cref{fig:bilateral:model_comp:ipsi}, this indicates that the assumptions underlying the introduction of the mixing parameter $\alpha$ are feasible.

%% TODO:
%% Back up this paragraph with a figure showing the correlations between LNL of the contralateral side.
One would expect that modelling the correlations between involvements of the contralateral \glspl{lnl} might suffer from the simplifying introduction of the mixing parameter $\alpha$, but this is hard to test, as cases where e.g. \gls{lnl} III is involved without \gls{lnl} II are very rare -- in this case it is only five patients. Also, the clinical debate centers around whether to treat or to spare the contralateral side as a whole when performing elective \gls{rt} or elective bilateral \gls{nd} \cite{biau_selection_2019,al-mamgani_contralateral_2017}. Sparing individual \glspl{lnl} is not yet debated. Therefore, a more complete model like $\mathcal{M}_\text{full}$, that might be able to capture correlations we cannot yet see due to insufficient data, are not worth the additional model complexity at this point.

A comparison of the log-evidence of the three models -- which we provide in \cref{table:bilateral:model_comp:evidences} -- supports our initial hypothesis that the mixing model $\mathcal{M}_\alpha$ well, even compared to the full model $\mathcal{M}_\text{full}$, while being significantly less complex. Besides \emph{decisive} evidence against the agnostic model (according to \cref{table:bayes_factor}), we also see that the accuracy $\mathcal{A}_\text{MC}(\beta=1)$ is almost the same for the mixing model $\mathcal{M}_\alpha$ and the full model $\mathcal{M}_\text{full}$. But the higher complexity from introducing two additional parameters is punished heavily both by the thermodynamically integrated log-evidence, and its approximation, the \gls{bic}. Therefore, from a Bayesian standpoint, we find \emph{decisive} evidence in favor of the mixing model $\mathcal{M}_\alpha$ with $\ln{K}_{\alpha\,\text{v}\,\text{full}} = 6.4$. Interestingly, the \gls{bic} seems to be a very close approximation, being always withing the standard deviation of the actual log-evidence for all shown models.

\Cref{fig:bilateral:model_comp:thermo_int} displays how -- using \gls{ti} -- the expected log-likelihood under the power posterior evolves over the course of a \gls{ti} round for each of the three compared models. It shows that the final accuracy $\mathcal{A}_\text{MC}(\beta=1)$ of the agnostic model $\mathcal{M}_\text{ag}$ is lower than of the other two models, which owe that to their ability to incorporate the tumor's extension over the mid plane into the prediction. However, while the mixing model $\mathcal{M}_\alpha$ and the full model $\mathcal{M}_\text{full}$ achieve the same fit to the data, the full model's accuracy rises for later $\beta$ values, which results in a lower log-evidence and a higher complexity penalty (see \cref{eq:ti:acc_vs_kl}) compared to the simpler mixing model.

\begin{table}
    \centering
    \begin{tabular}{|l|l|l|l|l|l|}
        \hline
        \textbf{Model} & \textbf{-- log-evidence} & \textbf{BIC/2} & \textbf{-- max. llh} & \textbf{-- mean llh} \\
        \hline
        $\mathcal{M}_\text{ag}$ & 1118.2 $\pm$ 1.8 & 1116.7 & 1088.3 & 1092.3 \\
        $\mathcal{M}_\alpha$ & 1093.3 $\pm$ 1.9 & 1093.1 & 1061.5 & 1065.7 \\
        $\mathcal{M}_\text{full}$ & 1099.7 $\pm$ 2.0 & 1098.2 & 1060.4 & 1065.5 \\
        \hline
    \end{tabular}
    \caption[
        Metrics for assessing three bilateral models
    ]{
        Metrics computed via \gls{ti} for the three bilateral models introduced in \cref{sec:bilateral:model_comp}: The negative log-evidence $\ln{Z}$ with the respective standard deviation in the first column, one half of the \gls{bic} in the second column, as well as the negative of the maximum and mean likelihood of the sampling procedures in columns three and four respectively. Note that the smaller the values given here, the better the performance of the respective model.
    }
    \label{table:bilateral:model_comp:evidences}
\end{table}

\begin{figure}
    \centering
    % \def\svgwidth{1.0\textwidth}
    \input{figures/thermo_int.pdf_tex}
    \caption[Plotted accuracy over the course of a thermodynamic integration round]{
        Expectation of the log-likelihood under the power posterior (\cref{eq:ti:power_post}) plotted against 64 inverse temperature steps $\beta$ for the three models. The accuracy on the y-axis is plotted on a log-scale, while the $\beta$ values, which themselves represent a fifth order annealing schedule, were plotted on an x-axis where the ticks were spaced according to a seventh order power rule. This was done to nicely visualize both the differences in accuracy and to better depict at which $\beta$ values the accuracies begin to rise.
    }
    \label{fig:bilateral:model_comp:thermo_int}
\end{figure}

\end{document}
