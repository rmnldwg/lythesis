\providecommand{\relativeRoot}{../..}
\documentclass[\relativeRoot/main.tex]{subfiles}
\graphicspath{\relativeRoot/figures/}


\begin{document}

\section{Mixture of HMM Models}
\label{sec:future:mixture}

Because we have defined the likelihood of a dataset as a product over the likelihoods for individual patients in \cref{sec:unilateral:formalism} (see for example \cref{eq:unilateral:llh_as_prod}), we implicitly assume that the lymphatic spread parameters of all patients in our datasets are from the same distribution. I.e., we do not allow different ``subgroups'' of patients that might have different spread characteristics.

If we want to capture different spread characteristics within a patient cohort, we would need to employ a so-called \emph{mixture model}. To explain this concept, we will loosely follow the descriptions in \citeauthorandlink{bishop_pattern_2006}, \citeauthorandlink{mackay_information_nodate}, and \citeauthorandlink{gelman_bayesian_2015}. Note that due to the way we have defined our variables earlier, we cannot stick to the notation of these books that usually call $\mathbf{X}$ the data and $\mathbf{Z}$ the latent variables. Rather, as defined in \cref{sec:previous_work:bayesian,sec:unilateral:formalism}, $\mathbf{X}$ represents the hidden state of metastatic involvement and $\mathbf{Z}$ a diagnosis or observation of that state. And a dataset of patients is -- as previously -- written as $\boldsymbol{\mathcal{Z}} = \{ \mathbf{Z}_i \}$ with $i \in [1, 2, \ldots, N]$ being the index for individual patients.

Before, we have assumed that all patients exhibit the same lymphatic spread characteristics, defined by one set of parameters $\theta$. We now drop that assumption and instead consider that it might be possible to categorize patients of a cohort into $K$ subgroups. To be able to capture which patient belongs to which subgroup, we introduce new \glspl{rv}: $G_{ik} = 1$, if patient $i$ belongs to subgroup $k$ and in that case all $G_{i\ell} = 0$ for $\ell \neq k$. We collect these assignment variables for each patient in a random matrix $\boldsymbol{\mathcal{G}} = \{ \mathbf{G}_i \}$. Together with the diagnoses of all patients, these subgroup assignments compose the \emph{complete data} $\{ \boldsymbol{\mathcal{Z}}, \boldsymbol{\mathcal{G}} \}$. However, we cannot know which patient belongs to which subgroup, since we do not even know how each subgroup is characterized in terms of their respective spread parameters $\theta_k$. All we have at hand for our inference, is the \emph{incomplete data} $\{ \boldsymbol{\mathcal{Z}} \}$.

Before, we have assumed that the observed diagnosis $\mathbf{Z}_i$ of patient $i$ was sampled from the distribution $\Probofgiven{\mathbf{Z}_i}{\theta}$. Now let us say we know there are $K$ subgroups among the patients in our dataset that exhibit different lymphatic progression characteristics defined by $\theta_k$ and $k \in [1, \ldots, K]$. If we define new \acrfullpl{rv} $G_{ik}$ that take on the value $G_{ik} = 1$ when the patient $i$ belongs to subgroup $k$ and $G_{i\ell} = 0$ for $\ell \neq k$, then we can write the distribution over the $i$-th patient's diagnosis as follows:
%
\begin{equation}
    \begin{aligned}
        P \left( \mathbf{Z}_i \right) &= \sum_{\mathbf{g}}{ \Probofgiven{\mathbf{Z}_i}{\boldsymbol{\theta}, \mathbf{G} = \mathbf{g}} P \left(\mathbf{G} = \mathbf{g}\right) } \\
        &= \sum_{k=1}^K{ \omega_k P_\text{HMM} \left( \mathbf{Z}_i \mid \theta_k \right) }
    \end{aligned}
\end{equation}
%
For the second line, we have written some terms in other forms: Because the group assignment $\mathbf{g}$ uses a ``1-of-$K$'' encoding, meaning only one of its $K$ elements can be one and all others must be zero, its probability can be written as
%
\begin{equation}
    P \left(\mathbf{g}\right) = \prod_{k=1}^K{ \omega_k^{g_k} }
\end{equation}
%
with $\omega_k = P \left(g_k = 1\right)$. And if we know to which subgroup patient $i$ belongs, we can use the \gls{hmm} likelihood from \cref{eq:unilateral:hmm_marginalize} to write
%
\begin{equation}
    \Probofgiven{\mathbf{Z}_i}{\theta_k, g_k = 1} = P_\text{HMM} \left( \mathbf{Z}_i \mid \theta_k \right)
\end{equation}
%
allowing us to restate
%
\begin{equation}
    \Probofgiven{\mathbf{Z}_i}{\boldsymbol{\theta}, \mathbf{g}} = \prod_{k=1}^K{ P_\text{HMM} \left( \mathbf{Z}_i \mid \theta_k \right)^{g_k} }
\end{equation}
%
A fundamental problem with such a mixture model now is that we only observe the so-called \emph{incomplete} data $\boldsymbol{\mathcal{Z}} = \left\{ \mathbf{z}_i \right\}$. The \emph{complete} dataset $\left\{ \mathbf{z}_i, \mathbf{g}_i \right\}$ of diagnoses along with the respective group labels for each patient would be necessary to perform inference using the complete data likelihood
%
\begin{equation}
    \Probofgiven{\mathbf{Z}, \mathbf{G}}{\boldsymbol{\theta}} = \Probofgiven{\mathbf{Z}}{\boldsymbol{\theta}, \mathbf{G} = \mathbf{g}} P \left(\mathbf{G} = \mathbf{g}\right)
\end{equation}
%
Now, if we knew the spread parameters for all subgroups $\boldsymbol{\theta}$, we could infer the group assignment for patient $i$ in a Bayesian fashion:
%
\begin{equation}
    \begin{aligned}
        \Probofgiven{g_k = 1}{\mathbf{Z}_i, \boldsymbol{\theta}} &= \frac{\Probofgiven{\mathbf{Z}_i}{\theta_k, g_k=1} P \left( g_k = 1 \right)}{\sum_{j=1}^K{\Probofgiven{\mathbf{Z}_i}{\theta_j, g_j=1} P \left( g_j = 1 \right)}} \\
        &= \frac{\omega_k P_\text{HMM} \left( \mathbf{Z}_i \mid \theta_k \right)}{\sum_{j=1}^K{\omega_j P_\text{HMM} \left( \mathbf{Z}_i \mid \theta_j \right)}}
    \end{aligned}
\end{equation}
%
And in turn, if we knew the group label $\mathbf{g}$ for patient $i$, we could infer that patient's spread parameters, e.g. through sampling. Unfortunately, solving for both at the same time results in a set of equations that mutually depend on each other. But there exists a family of algorithms that can solve for the group labels and parameters alternatingly, resulting in an iterative procedure called \gls{em}.

To formulate the \gls{em} algorithm for our problem, let us first collect the individual patient's assignments and diagnoses into matrices: As before $\boldsymbol{\mathcal{Z}} = \{ \mathbf{Z}_i \}$ for patients $i \in \left[ 1, 2, \ldots, N \right]$, and similarily for the group assignments $\boldsymbol{\mathcal{G}} = \{ \mathbf{G}_i \}$, so that now $g_{ik} = 1$ means that patient $i$ belongs to subgroup $k$.

As the name suggests, it consists of two steps:
\begin{enumerate}
    \item[(E)] Computing the \emph{expectation} of the complete data (log-)likelihood $\Probofgiven{\mathbf{Z}, \mathbf{G}}{\boldsymbol{\theta}}$ for the current estimate of the subgroup assignments $\Probofgiven{\mathbf{G}}{\mathbf{Z}, \boldsymbol{\theta}^\text{old}}$ using the current estimate of the model's parameters $\boldsymbol{\theta}^\text{old}$.
    \item[(M)] Maximize the expectation computed in the (E) step with respect to the parameters $\boldsymbol{\theta}$:
    \begin{equation}
        \boldsymbol{\theta}^\text{new} = \argmax_\theta{\sum_{\mathbf{g}}{\Probofgiven{\mathbf{Z}, \mathbf{g}}{\boldsymbol{\theta}} \Probofgiven{\mathbf{g}}{\mathbf{Z}, \boldsymbol{\theta}^\text{old}}}}
    \end{equation}
\end{enumerate}

\end{document}
